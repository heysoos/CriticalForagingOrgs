from plotting import plot_food
from plotting import plot_organism

import numpy as np
import operator
from itertools import combinations
import matplotlib.pyplot as plt
import copy

from math import atan2
from math import cos
from math import degrees
from math import floor
from math import radians
from random import random
from random import sample
from random import randint
from math import sin
from math import sqrt
from random import uniform

import os
import pickle
import time

# ------------------------------------------------------------------------------+
# ------------------------------------------------------------------------------+
# --- CLASSES ------------------------------------------------------------------+
# ------------------------------------------------------------------------------+
# ------------------------------------------------------------------------------+

class ising:
    # Initialize the network
    def __init__(self, settings, netsize, Nsensors=2, Nmotors=2, name=None):  # Create ising model

        self.size = netsize
        self.Ssize = Nsensors  # Number of sensors
        self.Msize = Nmotors  # Number of sensors
        self.radius = settings['org_radius']

        self.h = np.zeros(netsize)

        # self.J = np.zeros((self.size, self.size))

        self.J = np.random.random((self.size, self.size))*2 - 1
        self.J = (self.J + self.J.T) / 2
        np.fill_diagonal(self.J, 0)

        self.max_weights = 2

        self.maxRange = sqrt((settings['x_max'] - settings['x_min']) ** 2 +
                             (settings['y_max'] - settings['y_min']) ** 2)

        self.randomize_state()

        self.randomize_position(settings)

        # self.r = uniform(0, 360)  # orientation   [0, 360]
        # self.v = uniform(0, settings['v_max']/3)  # velocity      [0, v_max]
        # self.dv = uniform(-settings['dv_max'], settings['dv_max'])  # dv

        self.dx = 0
        self.dy = 0

        self.name = name

        self.Beta = 1.0
        # self.defaultT = max(100, netsize * 20)

        self.Ssize1 = 1 # FOOD ROTATIONAL SENSOR: sigmoid(theta)
        self.Ssize2 = 1 # FOOD DISTANCE SENSOR: sigmoid(distance)
        self.Ssize3 = 1 # DIRECTIONAL NEIGHBOUR SENSOR: dot-product distance normalized, see self.org_sens

        self.Msize1 = int(self.Msize/2)  # dv motor neuron


        # MASK USED FOR SETTINGS J/h TO 0
        self.maskJ = np.ones((self.size, self.size), dtype=bool)
        self.maskJ[0:self.Ssize, 0:self.Ssize] = False
        self.maskJ[-self.Msize: -self.Msize] = False
        self.maskJ[0:self.Ssize, -self.Msize:] = False
        np.fill_diagonal(self.maskJ, 0)
        self.maskJ = np.triu(self.maskJ)

        self.J[~self.maskJ] = 0

        # self.maskJtriu = np.triu(self.maskJ)

        self.disconnect_hidden_neurons(settings)

        self.maskh = np.ones(self.size, dtype=bool)
        self.maskh[0:self.Ssize] = False

        self.d_food = self.maxRange  # distance to nearest food
        self.r_food = 0  # orientation to nearest food
        self.org_sens = 0 # directional, 1/distance ** 2 weighted organism sensor
        self.fitness = 0

        self.assign_critical_values(settings)

        if not settings['BoidOn']:
            self.Update(settings, 0)

    def get_state(self, mode='all'):
        if mode == 'all':
            return self.s
        elif mode == 'motors':
            return self.s[-self.Msize:]
        elif mode == 'sensors':
            return self.s[0:self.Ssize]
        elif mode == 'non-sensors':
            return self.s[self.Ssize:]
        elif mode == 'hidden':
            return self.s[self.Ssize:-self.Msize]

    def get_state_index(self, mode='all'):
        return bool2int(0.5 * (self.get_state(mode) + 1))

    # Randomize the state of the network
    def randomize_state(self):
        self.s = np.random.randint(0, 2, self.size) * 2 - 1
        self.s = np.array(self.s, dtype=float)

        # SEE SENSOR UPDATE
        # random sensor states are generated by considering the sensor limitations

        random_rfood = (np.random.rand() * 360) - 180
        self.s[0] = random_rfood / 180

        random_dfood = np.random.rand() * self.maxRange
        self.s[1] = np.tanh(self.radius / (random_dfood ** 2 + 1e-6)) * 2 - 1

        random_dorg = np.random.rand() * self.maxRange
        self.s[2] = np.tanh((random_dorg)) * 2 - 1

    def randomize_position(self, settings):
        self.xpos = uniform(settings['x_min'], settings['x_max'])  # position (x)
        self.ypos = uniform(settings['y_min'], settings['y_max'])  # position (y)

        if settings['BoidOn']:
            self.v = (np.random.randn(2) * 2 - 1) * settings['v_max']
            self.dv = (np.random.randn(2) * 2 - 1) * settings['dv_max']
            self.dx = self.v[0] * settings['dt']
            self.dy = self.v[1] * settings['dt']
            # self.r = np.abs(np.arctan(self.ypos / self.xpos))
            self.r = np.arctan2(self.v[1], self.v[0]) * 180 / np.pi
        else:
            self.v = np.random.rand() * settings['v_max']
            self.dv = np.random.rand() * settings['dv_max']
            self.dx = self.v * cos(radians(self.r)) * settings['dt']
            self.dy = self.v * sin(radians(self.r)) * settings['dt']
            self.r = np.random.rand() * 360

    # Set random bias to sets of units of the system
    def random_fields(self, max_weights=None):
        if max_weights is None:
            max_weights = self.max_weights
        self.h[self.Ssize:] = max_weights * (np.random.rand(self.size - self.Ssize) * 2 - 1)

    # Set random connections to sets of units of the system
    def random_wiring(self, max_weights=None):  # Set random values for h and J
        if max_weights is None:
            max_weights = self.max_weights
        for i in range(self.size):
            for j in np.arange(i + 1, self.size):
                if i < j and (i >= self.Ssize or j >= self.Ssize):
                    self.J[i, j] = (np.random.rand(1) * 2 - 1) * self.max_weights

    def Move(self, settings):

        # print(self.s[-2:])
        # TODO: velocity coeffecient that can be mutated?
        # UPDATE HEADING - Motor neuron s.[-self.Msize:self.Msize1]
        self.r += (np.sum(self.s[-self.Msize:-self.Msize1]) / 2) * settings['dr_max'] * settings['dt']
        self.r = self.r % 360

        # UPDATE VELOCITY - Motor neuron s.[-self.Msize1:]
        self.v += (np.sum(self.s[-self.Msize1:]) / 2) * settings['dv_max'] * settings['dt']

        if self.v < 0:
            self.v = 0

        if self.v > settings['v_max']:
            self.v = settings['v_max']

        if self.r > settings['r_max']:
            self.r = settings['r_max']

        # print('Velocity: ' + str(self.v) +  str(self.s[-1]))

        # UPDATE POSITION
        self.dx = self.v * cos(radians(self.r)) * settings['dt']
        self.dy = self.v * sin(radians(self.r)) * settings['dt']
        self.xpos += self.dx
        self.ypos += self.dy

        # torus boundary conditions
        if abs(self.xpos) > settings['x_max']:
            self.xpos = -self.xpos

        if abs(self.ypos) > settings['y_max']:
            self.ypos = -self.ypos

    def UpdateSensors(self, settings):
        # self.s[0] = sigmoid(self.r_food / 180)
        # self.s[1] = sigmoid(self.d_food)

        # normalize these values to be between -1 and 1
        # TODO: make the numberators (gravitational constants part of the connectivity matrix so it can be mutated)
        self.s[0] = self.r_food / 180 # self.r_food can only be -180:180
        # self.s[1] = np.tanh(np.log10(self.radius / (self.d_food ** 2 + 1e-6)))  # self.d_food goes from 0 to ~
        # self.s[2] = np.tanh(np.log10(self.org_sens + 1e-10))
        self.s[1] = np.tanh(self.radius / (self.d_food ** 2 + 1e-6))*2 - 1  # self.d_food goes from 0 to ~
        self.s[2] = np.tanh((self.org_sens))*2 - 1
        # print(self.s[0:3])

    # Execute step of the Glauber algorithm to update the state of one unit
    def GlauberStep(self, i=None):
        if i is None:
            i = np.random.randint(self.size)
        eDiff = 2 * self.s[i] * (self.h[i] + np.dot(self.J[i, :] + self.J[:, i], self.s))
        if self.Beta * eDiff < np.log(1.0 / np.random.rand() - 1):  # Glauber
            self.s[i] = -self.s[i]

    # Execute time-step using an ANN algoirthm to update the state of all units
    def ANNStep(self):

        # SIMPLE MLP
        af = lambda x: np.tanh(x)  # activation function
        Jhm = self.J + np.transpose(self.J)  # connectivity for hidden/motor layers

        Jh = Jhm[:, self.Ssize:-self.Msize]  # inputs to hidden neurons
        Jm = Jhm[:, -self.Msize:]  # inputs to motor neurons

        # activate and update
        new_h = af(np.dot(self.s, Jh))
        self.s[self.Ssize:-self.Msize] = new_h

        new_m = af(np.dot(self.s, Jm))
        self.s[-self.Msize:] = new_m

        #  TODO: non-symmetric Jhm, need to change through to GA



    # Compute energy difference between two states with a flip of spin i
    def deltaE(self, i):
        return 2 * (self.s[i] * self.h[i] + np.sum(
            self.s[i] * (self.J[i, :] * self.s) + self.s[i] * (self.J[:, i] * self.s)))

    # Update states of the agent from its sensors
    def Update(self, settings, i=None):
        if i is None:
            i = np.random.randint(self.size)
        if i == 0:
            self.Move(settings)
            self.UpdateSensors(settings)
        elif i >= self.Ssize:
            self.GlauberStep(i)

    def SequentialUpdate(self, settings):
        for i in np.random.permutation(self.size):
            self.Update(settings, i)


    # Update all states of the system without restricted influences
    def SequentialGlauberStep(self, settings):
        thermalTime = int(settings['thermalTime'])

        self.UpdateSensors(settings) # update sensors at beginning

        # update all other neurons a bunch of times
        for j in range(thermalTime):
            perms = np.random.permutation(range(self.Ssize, self.size))
            for i in perms:
                self.GlauberStep(i)

        self.Move(settings) # move organism at end

    # Update all states of the system without restricted influences
    def ANNUpdate(self, settings):
        thermalTime = int(settings['thermalTime'])

        self.UpdateSensors(settings)  # update sensors at beginning

        # update all other neurons a bunch of times
        for j in range(thermalTime):
            self.ANNStep()

        self.Move(settings)  # move organism at end

    # update everything except sensors
    def NoSensorGlauberStep(self):
        perms = np.random.permutation(range(self.Ssize, self.size))
        for i in perms:
            self.GlauberStep(i)

    # update sensors using glauber steps (dream)
    def DreamSensorGlauberStep(self):
        perms = np.random.permutation(self.size)
        for i in perms:
            self.GlauberStep(i)

    # ensure that not all of the hidden neurons are connected to each other
    def disconnect_hidden_neurons(self, settings):
        numHNeurons = self.size - self.Ssize - self.Msize
        perms = list(combinations(range(self.Ssize, self.Ssize + numHNeurons), 2))
        numDisconnectedEdges = len(list(combinations(range(settings['numDisconnectedNeurons']), 2)))

        for i in range(0, numDisconnectedEdges):
            nrand = np.random.randint(len(perms))
            iIndex = perms[nrand][0]
            jIndex = perms[nrand][1]

            self.J[iIndex,jIndex] = 0
            # self.J[jIndex, iIndex] = 0

            self.maskJ[iIndex, jIndex] = False
            # self.maskJ[jIndex, iIndex] = False

        # self.maskJtriu = np.triu(self.maskJ)

    def assign_critical_values(self, settings):
        # LOAD ISING CORRELATIONS
        # filename = 'correlations-ising2D-size400.npy'
        # Cdist = np.load(filename)
        Cdist = settings['Cdist']

        self.m1 = np.zeros(self.size)
        self.C1 = np.zeros((self.size, self.size))
        for ii in range(self.size):
            for jj in range(max(ii + 1, self.Ssize), self.size):
                ind = np.random.randint(len(Cdist))
                self.C1[ii, jj] = Cdist[ind]

    # re-sort the assigned correlations from the critical ising model so that their order matches the order of the
    # actual correlations
    def sort_critical_correlations(self):
        c = self.C
        x = np.arange(np.prod(c.shape)).reshape(c.shape)[self.maskJ]  # index vector
        c = c[self.maskJ]

        c1 = self.C1[self.maskJ]

        orderc = np.argsort(c)
        orderc1 = np.argsort(c1)

        C1_new = np.zeros((self.size, self.size))

        # loop through index vector and re-sort assigned correlations to match order of actual correlations
        # for iEdge, index in enumerate(x):
        #     i_index = int(np.floor(index / self.size))
        #     j_index = int(index % self.size)
        #
        #     condition = np.subtract(orderc1, orderc[iEdge]) == 0
        #     # C1_index = int(np.extract(condition, orderc1))
        #     # C1_new[i_index, j_index] = c1[C1_index]
        #
        #     C1_new[i_index, j_index] = c1[condition]
        #     # C1_new[i_index, j_index] = c1[orderc1[condition]]

        for i, iEdge in enumerate(orderc):
            index = x[iEdge]
            i_index = int(np.floor(index / self.size))
            j_index = int(index % self.size)

            # condition = np.subtract(orderc1, orderc[i]) == 0

            C1_new[i_index, j_index] = c1[orderc1[i]]

        self.C1 = C1_new

    # mutate the connectivity matrix of an organism by stochastically adding/removing an edge
    def mutate(self, settings):
        # ADDS/REMOVES RANDOM EDGE DEPENDING ON SPARSITY SETTING, RANDOMLY MUTATES ANOTHER RANDOM EDGE

        # expected number of disconnected edges
        numDisconnectedEdges = len(list(combinations(range(settings['numDisconnectedNeurons']), 2)))
        totalPossibleEdges = len(list(combinations(range(self.size - self.Ssize - self.Msize), 2)))

        # number of (dis)connected edges
        connected = copy.deepcopy(self.maskJ)

        disconnected = ~connected
        np.fill_diagonal(disconnected, 0)
        disconnected = np.triu(disconnected)

        # things that need to be connected and not flagged to change
        connected[0:self.Ssize, :] = 0
        connected[:, -self.Msize:] = 0
        # things that need to be disconnected and not flagged to change
        disconnected[0:self.Ssize, -self.Msize:] = 0
        disconnected[0:self.Ssize, 0:self.Ssize] = 0

        numEdges = np.sum(connected)
        # positive value means too many edges, negative value means too little
        edgeDiff = numEdges - (totalPossibleEdges - numDisconnectedEdges)
        # edgeDiff = numEdges - numDisconnectedEdges

        # TODO: investigate the empty connectivity matrix here
        prob = sigmoid(edgeDiff)  # probability near 1 means random edge will be removed, near 0 means random edge added
        rand = np.random.rand()

        if prob >= rand:
            # remove random edge
            i, j = np.nonzero(connected)
            if len(i) > 0:
                randindex = np.random.randint(0, len(i))
                ii = i[randindex]
                jj = j[randindex]

                self.maskJ[ii, jj] = False
                self.J[ii, jj] = 0

                # TODO: is this a good way of making the code multi-purpose?
                try:
                    self.C1[ii, jj] = 0
                except NameError:
                    pass

            else:
                print('Connectivity Matrix Empty! Mutation Blocked.')

        else:
            # add random edge
            i, j = np.nonzero(disconnected)
            if len(i) > 0:
                randindex = np.random.randint(0, len(i))
                ii = i[randindex]
                jj = j[randindex]

                self.maskJ[ii, jj] = True
                self.J[ii, jj] = np.random.uniform(-1, 1) * self.max_weights
                # I.J[ii, jj] = np.random.uniform(np.min(I.J[I.Ssize:-I.Msize, I.Ssize:-I.Msize]) / 2,
                #                                 np.max(I.J[I.Ssize:-I.Msize, I.Ssize:-I.Msize]) * 2)
                try:
                    self.C1[ii, jj] = settings['Cdist'][np.random.randint(0, len(settings['Cdist']))]
                except NameError:
                    pass

            else:  # if connectivity matrix is full, just change an already existing edge
                i, j = np.nonzero(connected)

                randindex = np.random.randint(0, len(i))
                ii = i[randindex]
                jj = j[randindex]

                self.J[ii, jj] = np.random.uniform(-1, 1) * self.max_weights

        # MUTATE RANDOM EDGE
        i, j = np.nonzero(self.maskJ)

        randindex = np.random.randint(0, len(i))
        ii = i[randindex]
        jj = j[randindex]

        self.J[ii, jj] = np.random.uniform(-1, 1) * self.max_weights

        # MUTATE LOCAL TEMPERATURE
        if settings['mutateB']:
            deltaB = np.abs(np.random.normal(1, settings['sigB']))
            self.Beta = self.Beta * deltaB


class food():
    def __init__(self, settings):
        self.xpos = uniform(settings['x_min'], settings['x_max'])
        self.ypos = uniform(settings['y_min'], settings['y_max'])
        self.energy = 1

    def respawn(self, settings):
        self.xpos = uniform(settings['x_min'], settings['x_max'])
        self.ypos = uniform(settings['y_min'], settings['y_max'])
        self.energy = 1

# ------------------------------------------------------------------------------+
# ------------------------------------------------------------------------------+
# --- FUNCTIONS ----------------------------------------------------------------+
# ------------------------------------------------------------------------------+
# ------------------------------------------------------------------------------+


def dist(x1, y1, x2, y2):
    return sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)


def calc_heading(I, food):
    d_x = food.xpos - I.xpos
    d_y = food.ypos - I.ypos
    theta_d = degrees(atan2(d_y, d_x)) - I.r
    theta_d %= 360

    # keep the angles between -180:180
    if theta_d > 180:
        theta_d -= 360
    return theta_d


# Transform bool array into positive integer
def bool2int(x):
    y = 0
    for i, j in enumerate(np.array(x)[::-1]):
        y += j * 2 ** i
    return int(y)


# Transform positive integer into bit array
def bitfield(n, size):
    x = [int(x) for x in bin(int(n))[2:]]
    x = [0] * (size - len(x)) + x
    return np.array(x)


def TimeEvolve(isings, foods, settings, folder, rep):
    T = settings['TimeSteps']
    for I in isings:
        I.position = np.zeros((2, T))

    # Main simulation loop:
    if settings['plot'] == True:
        plt.clf()
        # plt.ion()
        fig, ax = plt.subplots()
        # fig.set_size_inches(15, 10)

    for t in range(T):

        # PLOT SIMULATION FRAME
        if settings['plot'] == True and (t % settings['frameRate']) == 0:
            plot_frame(settings, folder, fig, ax, isings, foods, t, rep)
            plt.pause(1e-5)
            plt.draw()
            plt.cla()

        interact(settings, isings, foods)

        if settings['BoidOn']:
            boid_update(isings, settings)
            for I in isings:
                I.position[:, t] = [I.xpos, I.ypos]


        else:
            for I in isings:
                if settings['ANN']:
                    I.ANNUpdate(settings)
                else:
                    I.SequentialGlauberStep(settings)
                I.position[:, t] = [I.xpos, I.ypos]



def TimeEvolve2(isings, BetaFactor, settings, T):


    # --- POPULATE THE ENVIRONMENT WITH FOOD ---------------+
    foods = []
    for i in range(0, settings['food_num']):
        foods.append(food(settings))

    # INITIALIZATIONS
    BetaOG = []
    for ii, I in enumerate(isings):
        # initialize variables
        I.pm = np.zeros((2, 1)) # position
        I.p2m = np.zeros((2, 1))

        I.Em = 0 # np.zeros((1, T)) # mean Energy
        I.E2m = 0 # np.zeros((1, T)) # mean Energy ** 2

        I.m = 0
        I.m2 = 0

        # set temperature
        BetaOG.append(I.Beta)
        I.Beta = I.Beta * BetaFactor  # scale by org's local temperature

        # random config
        I.randomize_position(settings)
        I.randomize_state()
        I.fitness = 0

    # TIME EVOLUTION / MEASUREMENTS
    print('Thermalizing...')
    for t in range(int(T / 10)):
        interact(settings, isings, foods) # interact with food, update raw sensor values.
        I.SequentialGlauberStep(settings)

    print('Beginning measurements...')

    if settings['plot'] == True:
        plt.clf()
        plt.ion()
        fig, ax = plt.subplots()
        folder = 'test'
        rep = 0
        # fig.set_size_inches(15, 10)

    for t in range(T):
        # if (t % 50) == 0 or t == 0:
        #     print(t)

        interact(settings, isings, foods)  # interact with food, update raw sensor values.

        if settings['plot'] == True and (t % settings['frameRate']) == 0:
            plot_frame(settings, folder, fig, ax, isings, foods, t, rep)
            plt.pause(1e-5)
            plt.draw()
            plt.cla()
        if settings['diagnostics'] == True and (t % settings['frameRate']) == 0:
            fitness = 0
            for I in isings:
                fitness += I.fitness
            print('t : %4i | F: %4f' % (t, fitness))

        for I in isings:
            I.SequentialGlauberStep(settings) # download sensor data into neurons, think (therm.), move.

            # don't include sensor neurons in measurements
            # sus M
            I.m += np.sum(I.s[I.Ssize:]) / float(T)
            I.m2 += np.sum(I.s[I.Ssize:]) ** 2 / float(T)

            # sus p
            p = [I.xpos, I.ypos]
            I.pm[:, 0] += np.divide(p, float(T))
            I.p2m[:, 0] += np.power(p, 2) / float(T)

            # heat spec.
            E = -(np.dot(I.s[I.Ssize:], I.h[I.Ssize:]) +
                  np.dot(np.dot(I.s[I.Ssize:], I.J[I.Ssize:, I.Ssize:]), I.s[I.Ssize:]))
            I.Em += E / float(T)
            I.E2m += E ** 2 / float(T)

    # reset betas back to original values in case of iterated use
    for ii, I in enumerate(isings):
        I.Beta = BetaOG[ii]

    return isings

# Dynamical Critical Learning Algorithm for poising units in a critical state
def HomeostaticGradient(isings, foods, settings, folder, rep):
    T = settings['TimeSteps']
    for I in isings:
        I.m = np.zeros(I.size)
        I.c = np.zeros((I.size, I.size))
        I.C = np.zeros((I.size, I.size))
        # I.var = np.zeros(I.size)

        I.position = np.zeros((2, T))

    # Main simulation loop:
    if settings['plot'] == True:
        plt.clf()
        plt.ion()
        fig, ax = plt.subplots()
        # fig.set_size_inches(15, 10)
    # start_time = time.time()
    for t in range(T):
        # print('Time = ' + str(t))
        # PLOT SIMULATION FRAME
        if settings['plot'] == True and (t % settings['frameRate']) == 0:
            plot_frame(settings, folder, fig, ax, isings, foods, t, rep)
            plt.pause(1e-5)
            plt.draw()
            plt.cla()

        # check_eat_food(settings, isings, foods)
        # calc_closest_food(isings, foods)
        interact(settings, isings, foods)

        for I in isings:
            I.SequentialGlauberStep(settings)
            I.position[:, t] = [I.xpos, I.ypos]
            I.m += I.s

            for iS in range(I.size):
                I.c[iS, iS + 1:] += I.s[iS] * I.s[iS + 1:]
                # I.c[iS, iS] += I.s[iS] ** 2
    # print('Time Elapsed: ' + str(int(time.time() - start_time)))

        # print(isings[0].position[:,t])

    # CALCULATE CORRELATIONS AND MEAN ACTIVATIONS TO GET: dh, dJ
    for I in isings:

        I.m /= T
        I.c /= T

        for iS in range(I.size):
            I.C[iS, iS + 1:] = I.c[iS, iS + 1:] - I.m[iS] * I.m[iS + 1:]
            # I.var[iS] = I.c[iS, iS] - I.m[iS] ** 2

        # resort correlations C1 to match the order of that of the actual C
        # TODO: Does this actually work the way it's supposed to?
        # TODO: Multiply by the sign?
        # TODO: frustrated critical ising models?
        I.sort_critical_correlations()

        I.dh = I.m1 - I.m
        I.dJ = I.C1 - I.C
        # I.dvar = I.var - 1

        I.dh[~I.maskh] = 0
        # I.dvar[~I.maskh] = 0
        I.dJ[~I.maskJ] = 0

def EvolutionLearning(isings, foods, settings, Iterations = 1):

    if settings['save_data'] == True:
        folder = 'save/sim-' + time.strftime("%Y%m%d-%H%M%S") + '/'
        if not os.path.exists(folder):
            os.makedirs(folder)
            os.makedirs(folder + 'isings')
            os.makedirs(folder + 'stats')
            os.makedirs(folder + 'figs')
    else:
        folder = None

    count = 0
    for rep in range(Iterations):
        TimeEvolve(isings, foods, settings, folder, rep)
        if settings['plot'] == True:
            plt.clf()

        # mutationrate[0], mutationrate[1] = mutation_rate(isings)

        if rep % settings['evolution_rate'] == 0 and settings['save_data'] == True:

            fitness, fitness_stat = food_fitness(isings)
            eat_rate = np.sum(fitness_stat)/settings['TimeSteps']

            if settings['mutateB']:
                Beta = []
                for I in isings:
                    Beta.append(I.Beta)

                mBeta = np.mean(Beta)
                stdBeta = np.std(Beta)
                maxBeta = np.max(Beta)
                minBeta = np.min(Beta)

        # save rate equal to evolutation rate
        # TODO: Add eatrate; make this useful
            mutationrate = None
            fitm = None
            fitC = None
            if settings['mutateB']:
                print(count, '|', eat_rate, mBeta, stdBeta, minBeta, maxBeta)
            else:
                print(count, '|', eat_rate)
            save_sim(folder, isings, fitness_stat, mutationrate, fitC, fitm, rep)

        if rep > settings['TimeStepsGrowth']:
            settings['plot'] = True

        count += 1

        if rep % settings['evolution_rate'] == 0:
            isings = evolve(settings, isings, rep)

def CriticalLearning(isings, foods, settings, Iterations=1):
    # settings['TimeSteps'] = 10
    mutationrate = np.zeros(2)

    u = 0.01

    if settings['save_data'] == True:
        folder = 'save/sim-' + time.strftime("%Y%m%d-%H%M%S") + '/'
        if not os.path.exists(folder):
            os.makedirs(folder)
            os.makedirs(folder + 'isings')
            os.makedirs(folder + 'stats')
            os.makedirs(folder + 'figs')
    else:
        folder = None

    count = 0
    l2 = 0.004
    for rep in range(Iterations):
        # CALCULATE self.dh AND self.dJ
        HomeostaticGradient(isings, foods, settings, folder, rep)
        if settings['plot'] == True:
            plt.clf()

        mutationrate[0], mutationrate[1] = mutation_rate(isings)
        fitness, fitness_stat = food_fitness(isings)
        eat_rate = np.sum(fitness_stat)/settings['TimeSteps']

        fitness = (fitness + 1) / 2

        if rep % settings['evolution_rate'] == 0: # save rate linked with evolutation rate
            fitC, fitm, Jmean, hmean = calc_fit(isings, mutationrate, eat_rate, count)

            if settings['mutateB']:
                Beta = []
                for I in isings:
                    Beta.append(I.Beta)

                mBeta = np.mean(Beta)

            if settings['mutateB']:
                print('%4i | F: %4f, T: %1.3f | Fc: %1.3f, Fm: %1.3f | J: %1.3f, H: %1.3f' %
                      (count, eat_rate, mBeta, fitC, fitm, Jmean, hmean))
            else:
                print('%4i | F: %4f | Fc: %1.3f, Fm: %1.3f | J: %1.3f, H: %1.3f' %
                      (count, eat_rate, fitC, fitm, Jmean, hmean))

                # print(count, '|', fitness_stat, fitC, fitm, '|', Jmean, hmean, )
            if settings['save_data'] == True:
                save_sim(folder, isings, fitness_stat, mutationrate, fitC, fitm, rep)

        if rep > settings['TimeStepsGrowth']:
            settings['plot'] = True

        count += 1

        iOrg = 0
        for I in isings:
            # I.J += fitness[iOrg] * (u * I.dJ - l2 * I.J)
            # I.h += fitness[iOrg] * (u * I.dh - l2 * I.h)
            I.J += u * I.dJ - l2 * I.J
            I.h += u * I.dh - l2 * I.h


            Vmax = I.max_weights
            for i in range(I.size):
                if np.abs(I.h[i]) > Vmax:
                    I.h[i] = Vmax * np.sign(I.h[i])
                for j in np.arange(i + 1, I.size):
                    if np.abs(I.J[i, j]) > Vmax:
                        I.J[i, j] = Vmax * np.sign(I.J[i, j])
            iOrg += 1

        if settings['evolution_toggle'] == True:
            if rep % settings['evolution_rate'] == 0:
                isings = evolve(settings, isings, rep)
        else:
            for I in isings:
                I.fitness = 0


def plot_frame(settings, folder, fig, ax, isings, foods, time, rep):
    # fig, ax = plt.subplots()
    fig.set_size_inches(9.6, 5.4)

    # plt.xlim([settings['x_min'] + settings['x_min'] * 0.25,
    #           settings['x_max'] + settings['x_max'] * 0.25])
    # plt.ylim([settings['y_min'] + settings['y_min'] * 0.25,
    #           settings['y_max'] + settings['y_max'] * 0.25])
    pad = 0.5

    plt.xlim([settings['x_min'] - pad,
              settings['x_max'] + pad])
    plt.ylim([settings['y_min'] - pad,
              settings['y_max'] + pad])

    # PLOT ORGANISMS
    for I in isings:
        plot_organism(settings, I.xpos, I.ypos, I.r, ax)

    # PLOT FOOD PARTICLES
    for food in foods:
        plot_food(settings, food.xpos, food.ypos, ax)

    # MISC PLOT SETTINGS
    ax.set_aspect('equal')
    frame = plt.gca()
    frame.axes.get_xaxis().set_ticks([])
    frame.axes.get_yaxis().set_ticks([])

    plt.figtext(0.025, 0.90, r'T_STEP: ' + str(time))

    # if settings['plotLive'] == True:
    #     plt.show()
    if settings['save_data'] == True:
        filename = folder + 'figs/iter-' + str(rep) + 'time-' + str(time).zfill(4) + '.png'
        plt.savefig(filename, dpi=300)
    # plt.close()

def calc_fit(isings, mutationrate, fitness_stat, count):
    fitC = []
    fitm = []
    Jmean = []
    hmean = []
    for I in isings:
        fitC.append(np.mean(np.abs(
            I.C1[I.maskJ] - I.C[I.maskJ])))

        fitm.append(np.mean(np.abs(I.m1[I.Ssize:] - I.m[I.Ssize:])))

        Jmean.append(np.max(np.abs(I.J)))
        hmean.append(np.max(np.abs(I.h[I.Ssize:])))
    fitC = np.max(fitC)
    fitm = np.mean(fitm)
    fit = fitC + fitm
    Jmean = np.mean(Jmean)  # average of the highest J values
    hmean = np.mean(hmean)  # average of the highest h values

    return fitC, fitm, Jmean, hmean

def food_fitness(isings):
    fitness = []
    for I in isings:
        fitness.append(I.fitness)

    fitness = np.array(fitness, dtype='float')
    mask = fitness != 0

    fitnessN = copy.deepcopy(fitness)
    fitnessN[mask] /= float(np.max(fitnessN))
    # fitness[mask] /= float(np.max(fitness))

    return fitnessN, fitness

def evolve(settings, I_old, gen):
    size = settings['size']
    nSensors = settings['nSensors']
    nMotors = settings['nMotors']

    I_sorted = sorted(I_old, key=operator.attrgetter('fitness'), reverse=True)
    I_new = []

    alive_num = int(settings['pop_size'] - settings['numKill'])
    elitism_num = int(alive_num/2) # only the top half of the living orgs can duplicate

    numMate = int(settings['numKill'] * settings['mateDupRatio'])
    numDup = settings['numKill'] - numMate

    for i in range(0, alive_num):
        I_new.append(I_sorted[i])

    # --- GENERATE NEW ORGANISMS ---------------------------+
    orgCount = settings['pop_size'] + gen * settings['numKill']

    # DUPLICATION OF ELITE POPULATION
    for dup in range(0, numDup):
        candidateDup = range(0, elitism_num)
        random_index = sample(candidateDup, 1)[0]

        name = copy.deepcopy(I_sorted[random_index].name) + 'm'
        I_new.append(ising(settings, size, nSensors, nMotors, name))

        #  TODO: need to seriously check if mutations are occuring uniquely
        # probably misusing deepcopy here, figure this shit out
        I_new[-1].Beta = copy.deepcopy(I_sorted[random_index].Beta)
        I_new[-1].J = copy.deepcopy(I_sorted[random_index].J)
        I_new[-1].h = copy.deepcopy(I_sorted[random_index].h)
        I_new[-1].maskJ = copy.deepcopy(I_sorted[random_index].maskJ)
        # I_new[-1].maskJtriu = I_sorted[random_index].maskJtriu

        try:
            I_new[-1].C1 = I_sorted[random_index].C1
        except NameError:
            pass

        # MUTATE SOMETIMES
        if np.random.random() < settings['mutationRateDup']:
            I_new[-1].mutate(settings)

        # random mutations in duplication

    # MATING OF LIVING POPULATION DOUBLE DIPPING ELITE
    for mate in range(0, numMate):
        # TODO: negative weight mutations?!
        # SELECTION (TRUNCATION SELECTION)
        candidatesMate = range(0, len(I_new)) # range(0, alive_num) to avoid double dipping
        random_index = sample(candidatesMate, 2)
        org_1 = I_sorted[random_index[0]]
        org_2 = I_sorted[random_index[1]]

        # CROSSOVER
        J_new = np.zeros((size, size))
        h_new = np.zeros(size)

        # load up a dummy maskJ which gets updated
        maskJ_new = np.zeros((size, size), dtype=bool)

        crossover_weight = random()

        # CROSS/MUTATE TEMPERATURE
        if settings['mutateB']:
            # folded normal distribution
            deltaB = np.abs( np.random.normal(1, settings['sigB']) )

            Beta_new = ( (crossover_weight * org_1.Beta) + \
                            ((1 - crossover_weight) * org_2.Beta) ) * deltaB
        else:
            Beta_new = org_1.Beta

        # CROSS WEIGHTS
        for iJ in range(0, size):
            crossover_weight = random()

            h_new[iJ] = (crossover_weight * org_1.h[iJ]) + \
                        ((1 - crossover_weight) * org_2.h[iJ])

            for jJ in range(iJ + 1, size):
                crossover_weight = random()

                # check if these hidden neurons are disconnected to begin with
                if org_1.maskJ[iJ, jJ] != 0 and org_2.maskJ[iJ, jJ] != 0:
                    J_new[iJ, jJ] = (crossover_weight * org_1.J[iJ, jJ]) + \
                                    ((1 - crossover_weight) * org_2.J[iJ, jJ])
                    maskJ_new[iJ, jJ] = org_1.maskJ[iJ, jJ]
                elif np.random.randint(2) == 0:
                    J_new[iJ, jJ] = org_1.J[iJ, jJ]
                    maskJ_new[iJ, jJ] = org_1.maskJ[iJ, jJ]
                else:
                    J_new[iJ, jJ] = org_2.J[iJ, jJ]
                    maskJ_new[iJ, jJ] = org_2.maskJ[iJ, jJ]

                if np.abs(J_new[iJ, jJ]) > org_1.max_weights:
                    J_new[iJ, jJ] = org_1.max_weights


        # TODO: include name of parents
        name = 'gen[' + str(gen) + ']-org[' + str(orgCount) + ']'
        I_new.append(ising(settings, size, nSensors, nMotors, name))

        I_new[-1].Beta = Beta_new
        I_new[-1].J = J_new
        I_new[-1].h = h_new
        I_new[-1].maskJ = maskJ_new

        # MUTATE IN GENERAL
        I_new[-1].mutate(settings)

        orgCount += 1

    for I in I_new:
        I.fitness = 0

    return I_new

def save_sim(folder, isings, fitness_stat, mutationrate, fitC, fitm, gen):
    filenameI = folder + 'isings/gen[' + str(gen) + ']-isings.pickle'
    filenameS = folder + 'stats/gen[' + str(gen) + ']-stats.pickle'

    if type(mutationrate) is not type(None):
        mutationh = mutationrate[0]
        mutationJ = mutationrate[1]
    else:
        mutationh = None
        mutationJ = None


    pickle_out = open(filenameI, 'wb')
    pickle.dump(isings, pickle_out)
    pickle_out.close()

    pickle_out = open(filenameS, 'wb')

    if type(mutationrate) is not type(None):
        pickle.dump((fitness_stat, (mutationh, mutationh ** 2), (mutationJ, mutationJ ** 2), fitC, fitm), pickle_out)
        pickle_out.close()
    else:
        pickle.dump(fitness_stat, pickle_out)
        pickle_out.close()


def mutation_rate(isings):
    for I in isings:

        hmutation = np.abs(I.dh[I.maskh])
        Jmutation = np.abs(I.dJ[I.maskJ])

    hmutation = np.mean(hmutation)
    Jmutation = np.mean(Jmutation)
    return hmutation, Jmutation

def sigmoid(x):
    y = 1/(1 + np.exp(-x))
    return y

def logit(x):
    y = np.log(x / (1 - x))
    return y

def check_eat_food(settings, isings, foods):
    for food in foods:
        for I in isings:

            food_org_dist = dist(I.xpos, I.ypos, food.xpos, food.ypos)

            # EAT/RESPAWN FOOD
            if food_org_dist <= 0.075:
                I.fitness += food.energy
                food.respawn(settings)

        # RESET DISTANCE AND HEADING TO NEAREST FOOD SOURCE
        I.d_food = I.maxRange
        I.r_food = 0

def calc_closest_food(isings, foods):
    for food in foods:
        for I in isings:

            # CALCULATE DISTANCE TO SELECTED FOOD PARTICLE
            food_org_dist = dist(I.xpos, I.ypos, food.xpos, food.ypos)

            # DETERMINE IF THIS IS THE CLOSEST FOOD PARTICLE
            if food_org_dist < I.d_food:
                I.d_food = food_org_dist
                I.r_food = calc_heading(I, food)

#TODO: double check if this is working as intended!
def interact(settings, isings, foods):
    for I in isings:
        I.d_food = I.maxRange
        I.r_food = 0
        I.org_sens = 0

        for food in foods:
            food_org_dist = dist(I.xpos, I.ypos, food.xpos, food.ypos)

            # EAT
            if food_org_dist <= settings['org_radius']:
                I.fitness += food.energy
                food.respawn(settings)

            # DETERMINE IF THIS IS THE CLOSEST FOOD PARTICLE
            if food_org_dist < I.d_food:
                I.d_food = food_org_dist
                I.r_food = calc_heading(I, food)

        for I2 in isings:

            if I != I2:
                org_org_dist = dist(I.xpos, I.ypos, I2.xpos, I2.ypos)
                org_org_heading = calc_heading(I, I2)

                # implement a directional sensor
                if abs(org_org_heading) > 90:
                    dot_org_heading = 0
                else:
                    dot_org_heading = np.cos(np.deg2rad(org_org_heading))

                I.org_sens += ((dot_org_heading * I.radius) / (org_org_dist + 1e-6) ** 2)




def update_ising(settings, I, t):
    I.SequentialUpdate(settings)
    I.position[:, t] = [I.xpos, I.ypos]
    I.m += I.s

    for iS in range(I.size):
        I.c[iS, iS + 1:] += I.s[iS] * I.s[iS + 1:]


#####################################
# BOID THINGS
#####################################

def boid_dv(isings, settings):
    vision_radius = 0.75
    N = len(isings)
    combos = list(combinations(range(0, len(isings)), r=2))

    ## CALCULATE CUMULATIVE AVERAGES
    # t_center = np.zeros(2)
    # t_velocity = np.zeros(2)
    pos_list = np.zeros((len(isings), 2))
    vel_list = np.zeros((len(isings), 2))
    for i, I in enumerate(isings):
        pos_list[i, :] = np.array((I.xpos, I.ypos))
        vel_list[i, :] = np.array((I.dx, I.dy))
        # t_center += pos_i
        # t_velocity += np.array((I.dx, I.dy))

    ## CALCULATE DISTANCE MATRIX
    dist_mat = np.zeros((len(isings), len(isings), 2))
    for pair in combos:
        ii = pair[0]
        jj = pair[1]

        pos_i = pos_list[ii]
        pos_j = pos_list[jj]

        dist_mat[ii, jj, :] = pointing_vector(pos_i, pos_j, settings)
        dist_mat[jj, ii, :] = -dist_mat[ii, jj, :]

    # for RULE 3: alternate form: (1/d^2 - 1/d^3)

    radius_mat = np.linalg.norm(dist_mat, axis=-1)  # used as a radius to localize global information by weighting
    radius_mat = np.dstack([radius_mat] * 2)
    # radius_mat = np.divide(radius_mat, np.sum(radius_mat, axis=0)).transpose()
    # radius_mat = np.multiply(radius_mat, np.sum(zeronaninf(1 / radius_mat), axis=0)).transpose()
    vision_mat = radius_mat < vision_radius
    # vision_mat = np.dstack([vision_mat] * 2)


    # corr_mat = -1 * np.sign(dist_mat) / np.dstack([np.power(radius_mat, 2)] * 2)
    # corr_mat[np.isinf(corr_mat)] = 0
    # corr_mat[np.isnan(corr_mat)] = 0

    localized_info = {}
    # localized_info['pos'] = np.divide(np.tile(pos_list, (len(isings), 1, 1)), np.dstack([np.power(radius_mat, 2)] * 2))
    # localized_info['corr'] = np.tanh(corr_mat)  # already 1/r^2 dependant
    # localized_info['vel'] = np.divide(np.tile(vel_list, (len(isings), 1, 1)), np.dstack([radius_mat] * 2))

    # pos_mat = np.tile(pos_list, (len(isings), 1, 1))
    # vel_mat = np.tile(vel_list, (len(isings), 1, 1))

    # localized_info['pos'] = np.tile(pos_list, (len(isings), 1, 1))
    localized_info['corr'] = np.divide(-1 * dist_mat, np.power(radius_mat, 2))
    localized_info['vel']  = np.tile(vel_list, (len(isings), 1, 1))


    for key, value in localized_info.items():
        new_value = zeronaninf(value)
        # new_value = np.tanh(value)
        localized_info.update({key: new_value})

    # corr_mat = np.tanh(corr_mat)

    ## CALCULATE INDIVIDUAL BOID FORCES
    for i, Ii in enumerate(isings):
        position_i = np.array((Ii.xpos, Ii.ypos))
        velocity_i = np.array((Ii.dx, Ii.dy))

        # RULE 1: percieved center
        # p_center_i = t_center - position_i
        # p_center_i = np.sum(localize_boid_info(pos_list, radius_mat[i, :]), axis=0)
        # p_center_i = (np.sum(
        #     localized_info['pos'][i, :, :] * vision_mat[i, :, :], axis=0) /
        #               np.sum(vision_mat[i, :, :], axis=0))

        cohesion_vector = (np.sum(dist_mat[i, :, :] * vision_mat[i, :, :], axis=0) /
                           np. sum(vision_mat[i, :, :], axis=0))

        # RULE 2: percieved correction
        # p_corr_i = np.sum(corr_mat[i, :, :], axis=0)
        # p_corr_i = np.sum(localize_boid_info(corr_mat[i, :, :], radius_mat[i, :]), axis=0)
        repulsion_vector = (np.sum(
            localized_info['corr'][i, :, :] * vision_mat[i, :, :], axis=0) /
                   np.sum(vision_mat[i, :, :], axis=0))

        # RULE 3: percieved velocity
        # p_velocity_i = t_velocity - velocity_i
        # p_velocity_i = np.sum(localize_boid_info(vel_list, radius_mat[i, :]), axis=0)
        p_velocity_i = (np.sum(
            localized_info['vel'][i, :, :] * vision_mat[i, :, :], axis=0) /
                       np.sum(vision_mat[i, :, :], axis=0))

        # average
        # p_center_i /= (N - 1)
        # p_corr_i /= (N - 1)
        # p_velocity_i /= (N - 1)
        random_dv = np.random.normal(size=2)

        # dv1 = p_center_i - position_i
        # dv2 = p_corr_i
        # dv3 = p_velocity_i - velocity_i

        # dv1 = p_center_i - position_i
        # dv2 = p_corr_i
        # dv3 = p_velocity_i - velocity_i

        # update
        # dv1 = 1 * (p_center_i - position_i)
        # dv2 = 0.1 * p_corr_i
        dv3 = 1 * (p_velocity_i - velocity_i)
        # dv4 = 0.001 * random_dv
        Ii.dvb = cohesion_vector + (0.2 * repulsion_vector) + dv3 + (0.005 * random_dv)

def boid_move(isings, settings):
    for I in isings:
        # dvb = I.dv1 + I.dv2 + I.dv3 + I.dv4
        # normdvb = np.linalg.norm(dvb)
        # if normdvb > settings['dv_max']:
        #     dvb /= normdvb
        #     I.dvb = dvb * settings['dv_max']
        # else:
        #     I.dvb = dvb

        I.v += I.dvb * settings['dt']
        I.r = np.arctan2(I.v[1], I.v[0]) * 180 / np.pi

        mag_v = np.sqrt(np.sum(np.power(I.v, 2)))

        if mag_v > settings['v_max']:
            I.v /= mag_v / settings['v_max']

        I.dx = I.v[0] * settings['dt']
        I.dy = I.v[1] * settings['dt']
        I.xpos += I.dx
        I.ypos += I.dy

        # torus boundary conditions
        I.xpos = (I.xpos + settings['x_max']) % settings['x_max']
        I.ypos = (I.ypos + settings['y_max']) % settings['y_max']

        # if abs(I.xpos) > settings['x_max']:
        #     # I.xpos = -I.xpos
        #     # I.xpos = -1 * np.sign(I.xpos) * settings['x_max']
        #     I.xpos = -1 * np.sign(I.xpos) * (settings['x_max'] - np.abs(I.xpos) % settings['x_max'])
        #
        # if abs(I.ypos) > settings['y_max']:
        #     # I.ypos = -I.ypos
        #     # I.ypos = -1 * np.sign(I.ypos) * settings['y_max']
        #     I.ypos = -1 * np.sign(I.ypos) * (settings['y_max'] - np.abs(I.ypos) % settings['y_max'])

# Derivative of neuron output
def transfer_derivative(output):
    return (1 - np.power(np.tanh(output), 2))

# Backpropogate error and update neuron weights
# def boid_backprop_error(isings):
#
#     for I in isings:
#         I.error =


# def boid_learn(isings):
#     boid_dv(isings)  # calculate boid dv
#     boid_backprop_error(isings)  # calculate error w.r.t. boid activations

def boid_update(isings, settings):
    boid_dv(isings, settings)  # Calculate boid dv
    boid_move(isings, settings)  # Apply boid dv

def localize_boid_info(global_vec, dist_vec):
    normalized = np.divide(global_vec, np.transpose(np.tile(dist_vec, (2,1))))
    normalized = zeronaninf(normalized)
    return normalized

def zeronaninf(mat):
    mat[np.isinf(mat)] = 0
    mat[np.isnan(mat)] = 0
    return mat

def pointing_vector(pos_i, pos_j, settings):
    L = [settings['x_max'] - settings['x_min'], settings['y_max'] - settings['y_min']]
    diff = pos_j - pos_i
    for dim in range(len(L)):
        diff[dim] = (diff[dim] +
                     (np.abs(diff[dim]) > L[dim] / 2) * -1 * (1 - 2 * (diff[dim] < L[dim] / 2)) * L[dim])
    return diff
# def boid_error(isings):
#
#
# def af_derivative(self):

